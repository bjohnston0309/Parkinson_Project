{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing the necessary Python libraries and data needed for the calculations of the time lag\n",
    "\n",
    "# Python lib import \n",
    "import csv\n",
    "import PyQt5\n",
    "import warnings\n",
    "import scipy as sc\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "from functools import reduce\n",
    "from math import log\n",
    "from scipy.stats import rankdata as rd\n",
    "from scipy.stats import norm as nm\n",
    "from scipy.stats import ttest_ind as tt\n",
    "from scipy import optimize as op\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.signal import argrelmin, argrelmax, find_peaks, detrend\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, Column\n",
    "\n",
    "# Ignoring warnings printed to screen\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "hdulist = fits.open('../../../Real Data/Healthy_Control_Data/Four_dots_static.fits')\n",
    "data = hdulist[0].data\n",
    "\n",
    "# Getting t data\n",
    "t = np.linspace(0,500,500)\n",
    "\n",
    "# Extracting x data\n",
    "x = [ [] for i in range(46)]\n",
    "x11 = [[] for i in range(46)]\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    x[i] = data[0,i,0,:]\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    x11[i] = detrend(x[i], axis=-1, type='linear')\n",
    "\n",
    "x1 = np.array(x11)\n",
    "\n",
    "# Extracting y data\n",
    "y = [ [] for i in range(46)]\n",
    "y11 = [[] for i in range(46)]\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    y[i] = data[0,i,1,:]\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    y11[i] = detrend(y[i], axis=-1, type='linear')\n",
    "\n",
    "y1 = np.array(y11)\n",
    "\n",
    "# Finding r data\n",
    "r1 = np.sqrt(x1**2 + y1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a function to calculate mutual information between a time series x(t) and x(t + tau)\n",
    "\n",
    "def MI_single(x0, x1, h='sturge', ranking=True):\n",
    "\n",
    "    # Determining number of points for each input x0 and x1\n",
    "    Nx0 = len(x0)\n",
    "    Nx1 = len(x1)\n",
    "    if Nx0 == Nx1:\n",
    "        N = Nx0\n",
    "    else:\n",
    "        N = min([Nx0, Nx1])\n",
    "    \n",
    "    # Performing ranking of data\n",
    "    if ranking == True:\n",
    "        x0 = rd(x0, method='ordinal')\n",
    "        x1 = rd(x1, method='ordinal')\n",
    "\n",
    "    # Calculating the number of bins to use for the histograms x0, x1 abnd (x0,x1)\n",
    "    if h == 'sturge':\n",
    "        Bx0 = np.log2(Nx0) + 1\n",
    "        Bx1 = np.log2(Nx1) + 1\n",
    "        B = [Bx0, Bx1]\n",
    "        B = np.round(np.array(B)).astype(int)     # Ensuring bin is an integer value\n",
    "    \n",
    "    # Calculating 1D histograms for x0 and x1\n",
    "    Hx0 = np.histogram(x1, bins = int(B[0])) [0]\n",
    "    Hx1 = np.histogram(x1, bins = int(B[1])) [0]\n",
    "\n",
    "    #  Calculating 2D histogram for (x0, x1)\n",
    "    Hx0x1 = np.histogram2d(x0, x1, bins = B) [0]\n",
    "\n",
    "    # Working out the probabilities needed for the AMI factor\n",
    "    Px0 = Hx0/N\n",
    "    Px1 = Hx1/N\n",
    "    Px0x1 = Hx0x1/N\n",
    "\n",
    "    # Performing the AMI factor calculation \n",
    "    I_initial = Px0x1*np.log(Px0x1/(Px1*Px1))\n",
    "    NaN_check = np.isnan(I_initial)                     # Checking which numbers in data are NaN  np.nansum\n",
    "    I_initial[NaN_check] = 0                            # Changing NaN entries in series to 0\n",
    "    I = sum(sum(I_initial))\n",
    "\n",
    "    # Finishing off function and returning value I\n",
    "    return(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a function to evaluate mutual information factor as a function of lag\n",
    "\n",
    "def MI_time_delay(timeseries, plotting=True):\n",
    "\n",
    "    # Initialising values and constants\n",
    "    max_delay = 150\n",
    "    I = []                     # Initialising AMI array\n",
    "    tau = []                   # Initialising tau array \n",
    "    delay = 0\n",
    "\n",
    "    # Performing the analysis\n",
    "    while delay < max_delay:\n",
    "        delay = delay + 1\n",
    "        x0 = timeseries[:-delay]                # All terms besides last term\n",
    "        x1 = timeseries[delay:]                 # All terms besides first term\n",
    "        I.append(MI_single(x0,x1))\n",
    "        tau.append(delay)\n",
    "\n",
    "    return(tau, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to compute takens emedded data for a specified delay and embedding dimension\n",
    "\n",
    "def takens_embedding(data, delay, dimension):\n",
    "\n",
    "    if delay*dimension > len(data):\n",
    "        raise NameError('Delay times dimension exceeds length of data')       # Ensures that delay is not going to be too large such that it is larger than the data length \n",
    "    \n",
    "    embedded_data = np.array([data[0:len(data)-delay*dimension]])\n",
    "\n",
    "    for i in range(1, dimension):\n",
    "        embedded_data = np.append(embedded_data, [data[i*delay:len(data) - delay*(dimension - i)]], axis=0)\n",
    "\n",
    "    return embedded_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to calculate percentage of false nearest neighbours for a range of embedding dimensions \n",
    "\n",
    "def false_nearest_neighbors(data,delay,embedding_dimension):\n",
    "\n",
    "    embedded_data = takens_embedding(data, delay, embedding_dimension);\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='auto').fit(embedded_data.transpose())\n",
    "    distances, indices = nbrs.kneighbors(embedded_data.transpose())\n",
    "\n",
    "    epsilon = np.std(distances.flatten())\n",
    "    nFalseNN = 0\n",
    "\n",
    "    for i in range(0, len(data)-delay*(embedding_dimension+1)):\n",
    "        if (0 < distances[i, 1]) and (distances[i, 1] < epsilon) and ( (abs(data[i+embedding_dimension*delay] - data[indices[i,1]+embedding_dimension*delay]) / distances[i,1]) > 10):\n",
    "            nFalseNN += 1;\n",
    "    return nFalseNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to compute the power specttrum of the phase space\n",
    "\n",
    "def power_spectrum(data_array,time):\n",
    "\n",
    "    fouriert_1 = sc.fft.rfft(data_array, len(time))\n",
    "    fourier_freq = sc.fft.rfftfreq(len(time), d = 1e-3)\n",
    "    power_spec = np.abs(fouriert_1)**2\n",
    "\n",
    "    return power_spec, fourier_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing averaged mutual information in x for each repetition\n",
    "\n",
    "# Setting up arrays\n",
    "tau_x = [[] for i in range(46)]\n",
    "I_x = [[] for i in range(46)]\n",
    "\n",
    "# Determining averaged mutual information for each repetition \n",
    "for i in range(46):\n",
    "\n",
    "    tau_x[i], I_x[i] = MI_time_delay(x1[i])\n",
    "\n",
    "# Calculating mean averaged mutual information\n",
    "tau_xav = np.sum(tau_x, axis=0)/46\n",
    "I_xav = np.sum(I_x, axis=0)/46\n",
    "\n",
    "# # Plotting mean averaged mutual information\n",
    "plt.plot(tau_xav, I_xav)\n",
    "plt.plot(tau_xav[16], I_xav[16], 'x', markersize=12, color='r')\n",
    "plt.xlabel('$Lag$', fontsize=16)\n",
    "plt.ylabel('<Mutual information> ($nats$)', fontsize=16)\n",
    "plt.title('Mutual information plot - x data', fontsize=20, pad=20)\n",
    "plt.xlim(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determining the values of tau for x data repetitions\n",
    "\n",
    "tau_xvalues = [[] for i in range(46)]\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    tau_xvalues[i] = MI_minima(tau_x[i], I_x[i])\n",
    "\n",
    "\n",
    "# Calculating mean value of tau\n",
    "tau_xmean = np.sum(tau_xvalues)/46\n",
    "\n",
    "# Calculating standard deviation of tau\n",
    "tau_sdx = np.std(tau_xvalues)\n",
    "\n",
    "print('Mean lag in x direction =', np.int(tau_xmean))\n",
    "print(tau_sdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### False Nearest Neighbours for each x repetition\n",
    "\n",
    "# Setting up arrays \n",
    "nFNN_x = [[] for i in range(46)]\n",
    "\n",
    "# Calculating percentage of false nearest neighbours for each repetition\n",
    "for i in range(46):\n",
    "\n",
    "    for j in range (1,7):\n",
    "\n",
    "        nFNN_x[i].append(false_nearest_neighbors(x1[i],tau_xvalues[i],j) / len(x1[i]))\n",
    "\n",
    "# Calculating mean false nearest neighbours\n",
    "nFNN_xav = np.sum(nFNN_x, axis=0)/46\n",
    "\n",
    "nFNN_xav1 = [0.65, nFNN_xav[1], nFNN_xav[2], nFNN_xav[3], nFNN_xav[4], nFNN_xav[5]]\n",
    "\n",
    "print(nFNN_xav)\n",
    "\n",
    "# Plotting mean false nearest neighbours\n",
    "plt.plot(range(1,7), nFNN_xav1)\n",
    "plt.plot(3,nFNN_xav1[2],'x', color='red', markersize=10)\n",
    "plt.xlabel('embedding dimension', fontsize=16);\n",
    "plt.ylabel('<Fraction of fNN>', fontsize=16);\n",
    "plt.title('False nearest neighbours vs dimension - x data', fontsize=20, pad=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing phase space reconstruction for x data \n",
    "\n",
    "# Embedding data \n",
    "embedded_x_final = []\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    embedded_x_final.append(takens_embedding(x1[i],tau_xvalues[i],3))\n",
    "\n",
    "\n",
    "# Plotting repetiton specific phase spaces\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8,6)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(embedded_x_final[10][0], embedded_x_final[10][1], embedded_x_final[10][2])\n",
    "ax.set_xlabel('$x(t)$', fontsize=14)\n",
    "ax.set_ylabel('$x(t+$'+str(tau_xvalues[0])+')', fontsize=14)\n",
    "ax.set_zlabel('$x(t+$'+str(2*tau_xvalues[0])+')', fontsize=14)\n",
    "ax.set_title('Parkinsons - x', fontsize=20, pad=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Power spectrum for each x repetition\n",
    "\n",
    "# Setting up arrays\n",
    "power_spectrum_x = []\n",
    "freq_x = [[] for i in range(46)]\n",
    "power_x = [[] for i in range(46)]\n",
    "sum_fpx = [[] for i in range(46)]\n",
    "sum_fx = [[] for i in range(46)]\n",
    "mean_freqx = [[] for i in range(46)]\n",
    "period_x = [[] for i in range(46)]\n",
    "\n",
    "\n",
    "# Calculating the power spectrum for x data\n",
    "for i in range(46):\n",
    "\n",
    "    power_spectrum_x.append(power_spectrum(x1[i],t))\n",
    "\n",
    "for i in range(46):\n",
    "    \n",
    "    freq_x[i] = power_spectrum_x[i][:][:][:][1]\n",
    "    power_x[i] = power_spectrum_x[i][:][:][:][0]\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    sum_fpx[i] = np.sum(freq_x[i]*power_x[i])\n",
    "    sum_fx[i] = np.sum(freq_x[i])\n",
    "\n",
    "for i in range(46):\n",
    "\n",
    "    mean_freqx[i] = sum_fpx[i]/sum_fx[i]\n",
    "    period_x[i] = 1/mean_freqx[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nearest neighbours for x data \n",
    "\n",
    "# Setting up arrays\n",
    "nearest_neighbours_x = [[] for i in range(46)]\n",
    "distances_x = [[] for i in range(46)]\n",
    "indices_x = [[] for i in range(46)]\n",
    "\n",
    "# Calculating nearest neighbours\n",
    "for i in range(46):\n",
    "    \n",
    "    for j in range(len(x1[i])):\n",
    "\n",
    "        nearest_neighbours_x[i] = NearestNeighbors(n_neighbors=200, algorithm='auto').fit(embedded_x_final[i].transpose())\n",
    "        distances_x[i], indices_x[i] = nearest_neighbours_x[i].kneighbors(embedded_x_final[i].transpose())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Divergence for x data \n",
    "\n",
    "# Initialising arrays needed for divergence calculation\n",
    "N = 300\n",
    "separation_x1 = [ [] for i in range(N)]\n",
    "lags_x = []\n",
    "xx_1 = [ [] for i in range(N)]\n",
    "lyapunovs_x = []\n",
    "lyapunovs_xerr = []\n",
    "all_divergencex = [[] for i in range(46)]\n",
    " \n",
    "\n",
    "for k in range(46):\n",
    "\n",
    "    separation_x1 = [[] for i in range(N)]\n",
    "    lags_x = []\n",
    "    xx_1 = [[] for i in range(N)]\n",
    "\n",
    "    eps = period_x[k] \n",
    "    oooo = embedded_x_final[k]\n",
    "    indi = indices_x[k]\n",
    "\n",
    "    # Extracting time differences between nearest neighbours\n",
    "    for i in range(N):\n",
    "        xx_1[i] = indi[i] - i\n",
    "\n",
    "    xx_2 = np.array(xx_1)\n",
    "    times_x = xx_2*1e-3\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        m_x = 0\n",
    "\n",
    "        while np.abs(times_x[i][m_x]) < eps and m_x < 199:\n",
    "\n",
    "            m_x = m_x + 1\n",
    "\n",
    "        lags_x.append(times_x[i][m_x]) \n",
    "\n",
    "    lags_x1 = np.array(lags_x)/1e-3\n",
    "    lags_x2 = lags_x1.astype(int)\n",
    "\n",
    "\n",
    "    # Calculating the divergence for Lyapunov exponent calculation\n",
    "    for i in range(0,N):\n",
    "        \n",
    "        for j in range(0,N):\n",
    "\n",
    "            try:\n",
    "\n",
    "                divv1 = np.sqrt((oooo[0,i+j+lags_x2[i]] - oooo[0,i+j])**2 + (oooo[1,i+j+lags_x2[i]] - oooo[1,i+j])**2 + (oooo[2,i+j+lags_x2[i]] - oooo[2,i+j])**2)\n",
    "                separation_x1[j].append(divv1)\n",
    "\n",
    "            except IndexError:\n",
    "                separation_x1[j].append(np.nan)\n",
    "\n",
    "\n",
    "    sep_x1 = np.array(separation_x1)\n",
    "\n",
    "    # Taking the logarithm of the divergence array\n",
    "    logsep_x1 = [ [] for i in range(len(sep_x1))]\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        logsep_x1[i] = np.log(sep_x1[i])\n",
    "\n",
    "    logsep_x1 = np.array(logsep_x1)\n",
    "    df_x=pd.DataFrame(logsep_x1)\n",
    "    df_x_interpolate=df_x.interpolate(limit_direction='both')\n",
    "    logsep_x2=pd.DataFrame.to_numpy(df_x_interpolate)\n",
    "\n",
    "    # Calculating the averaged ln(divergence)\n",
    "    av_log_div_x = np.mean(logsep_x2, axis = 1)\n",
    "    df_xx=pd.DataFrame(av_log_div_x)\n",
    "    df_xx=df_xx.replace(-np.inf, np.nan)\n",
    "    df_xx_interpolate=df_xx.interpolate(limit_direction='both')\n",
    "    av_log_div_x2=pd.DataFrame.to_numpy(df_xx_interpolate)\n",
    "\n",
    "    # Performing the linear regression calculation\n",
    "    t_regx = t[0:60].reshape(-1,1)\n",
    "    divx_reg = av_log_div_x2[0:60].reshape(-1,1)\n",
    "\n",
    "    reg_x = LinearRegression().fit(t_regx, divx_reg)\n",
    "    grad_x = reg_x.coef_.item()\n",
    "    intercept_x = reg_x.intercept_.item()\n",
    "\n",
    "    resx = av_log_div_x2[0:60] - (t[0:60]*grad_x + intercept_x)\n",
    "    resx_sq = np.sum(resx**2)\n",
    "    tmeanx = np.mean(t[0:60])\n",
    "    ttx = np.sum((t[0:60]-tmeanx)**2)\n",
    "\n",
    "    error_x = np.sqrt((1/58)*(resx_sq/ttx))\n",
    "    lyapunovs_x.append(grad_x)\n",
    "    lyapunovs_xerr.append(error_x)\n",
    "    all_divergencex[k].append(av_log_div_x2)\n",
    "\n",
    "lyapunovs_xmean = np.mean(lyapunovs_x)\n",
    "lyapunovs_sdx = np.std(lyapunovs_x)\n",
    "\n",
    "print('The mean value of lyapunov exponents for x repetitions is', lyapunovs_xmean)\n",
    "print(lyapunovs_sdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting averaged divergence for x data\n",
    "\n",
    "av_divx = np.sum(all_divergencex, axis=0)/46\n",
    "\n",
    "av_divx1=av_divx.reshape(300,)\n",
    "\n",
    "# Performing the linear regression calculation\n",
    "t_regx1 = t[2:40].reshape(-1,1)\n",
    "divx_reg1 = av_divx1[2:40].reshape(-1,1)\n",
    "\n",
    "reg_x1 = LinearRegression().fit(t_regx1, divx_reg1)\n",
    "grad_x1 = reg_x1.coef_.item()\n",
    "intercept_x1 = reg_x1.intercept_.item()\n",
    "\n",
    "resx1 = av_divx1[2:40] - (t[2:40]*grad_x1 + intercept_x1)\n",
    "resx_sq1 = np.sum(resx**2)\n",
    "tmeanx = np.mean(t[2:40])\n",
    "ttx1 = np.sum((t[2:40]-tmeanx)**2)\n",
    "\n",
    "error_x1 = np.sqrt((1/38)*(resx_sq1/ttx1))\n",
    "\n",
    "plt.plot(t[1:100], av_divx1[1:100])\n",
    "plt.plot(t[2:40], t[2:40]*grad_x1 + intercept_x1)\n",
    "plt.xlabel('Time (ms)', fontsize=16)\n",
    "plt.ylabel('<ln(divergence)> (arcmin)', fontsize=16)\n",
    "plt.title('Divergence of x data trajectories', fontsize=20, pad=20)\n",
    "\n",
    "rscore_x = r2_score(av_divx1[2:40], t[2:40]*grad_x1 + intercept_x1)\n",
    "mean_errx = mean_squared_error(av_divx1[2:40], t[2:40]*grad_x1 + intercept_x1)\n",
    "\n",
    "print(grad_x1)\n",
    "print(mean_errx)\n",
    "print(rscore_x)\n",
    "print(error_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing T-test between Parkinso's and control participant for x data\n",
    "\n",
    "t_patientx = lyapunovs_x\n",
    "t_controlx = [0.01765627331455689, 0.012681150466437757, 0.020516774227012393, 0.01497865336011384, 0.024826263834485114, 0.003848403480972742, 0.0075960087742760205, 0.005290220126460295, 0.010024605869547747, 0.0046611347492231375, 0.01438726685116858, 0.007784254129626441, 0.012539216669978632, 0.0165496486747158, 0.019613956695817572, 0.014048506763748882, 0.013387101499709127, 0.0031957656049769246, 0.011314532168966975, 0.012329519111002822, 0.014217457729683282, 0.012502313802872785, 0.010575841251180645, -0.001811745815571069, 0.007358029269456156, 0.01482539304261262, 0.015682957303024214, 0.007349580045030007, 0.016981321085743385, 0.008148401209969791, 0.007409589823571574, 0.01650054938199119, 0.012896785302120472, 0.008804631259729022, 0.013786305113871196, 0.015854212036596618, 0.009345630588459495, 0.02129832636742016, 0.014684630889070334, 0.010536314699870123, 0.012130646252518248, 0.010468336607669083, 0.0033527344517116434, 0.024080092867893536, 0.013161449552121143, 0.013348949519345897]\n",
    "\n",
    "mu_patientx = np.mean(t_patientx)\n",
    "mu_controlx = np.mean(t_controlx)\n",
    "\n",
    "sd_patientx = np.std(t_patientx)\n",
    "sd_controlx = np.std(t_controlx)\n",
    "\n",
    "ttest_x = tt(t_patientx, t_controlx, equal_var=False)\n",
    "\n",
    "print(ttest_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the histograms and fitted distributions for x data \n",
    "\n",
    "_, bins_xp, _ = plt.hist(t_patientx, 30, density=1, alpha=0.2, color='r', histtype='bar', ec='r')\n",
    "_, bins_xc, _ = plt.hist(t_controlx, 30, density=1, alpha=0.2, color='b', histtype='bar', ec='b')\n",
    "\n",
    "mu_xp, sigma_xp = nm.fit(t_patientx)\n",
    "mu_xc, sigma_xc = nm.fit(t_controlx)\n",
    "\n",
    "best_xp = nm.pdf(bins_xp, mu_xp, sigma_xp)\n",
    "best_xc = nm.pdf(bins_xc, mu_xc, sigma_xc)\n",
    "\n",
    "plt.plot(bins_xp, best_xp, color='r', linewidth=2.5)\n",
    "plt.plot(bins_xc, best_xc, color='b', linewidth=2.5)\n",
    "plt.legend(['Parkinson', 'Control'])\n",
    "plt.xlabel('LLE (arcmin/ms)', fontsize=16)\n",
    "plt.ylabel('Density', fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
